{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundamentos de la red neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En su implementación se utilizan conjuntos de unidades básicas de procesamiento, a las que se les denomina neuronas, organizadas en capas y conectadas entre sí. Cada una de las neuronas agrega sus entradas y realiza una operación sobre ella mediante una función de activació"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementación de una red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Declaramos la clases\n",
    "class MisNeuronas:\n",
    "    def __init__(self, sample, exit, learn_rate=0.01, epoch_number=1000, bias=-1):\n",
    "        # Atributos de la clase\n",
    "        self.sample = sample # Datos de entrenamiento\n",
    "        self.exit = exit # Salida esperada para cada dato\n",
    "        self.learn_rate = learn_rate # Que tanto aprendera la red\n",
    "        self.epoch_number = epoch_number\n",
    "        self.bias = bias # Bias de la red\n",
    "        self.number_sample = len(sample) # Numero de ejemplos\n",
    "        self.col_sample = len(sample[0]) # Columnas de los datos\n",
    "        self.weight = [] # Lista de pesos\n",
    "        \n",
    "    def trannig(self): # Metodo de entrenamiento\n",
    "            for sample in self.sample: # Se recorren los datos de entrenamiento\n",
    "                sample.insert(0, self.bias) # Se inserta el bias en la primera pocisión\n",
    "\n",
    "            for i in range(self.col_sample):\n",
    "                self.weight.append(random.random()) # Asignamos pesos aleatorios\n",
    "\n",
    "            self.weight.insert(0, self.bias) # Insertamos el bias en los pesos\n",
    "\n",
    "            epoch_count = 0\n",
    "\n",
    "            while True:\n",
    "                erro = False\n",
    "                for i in range(self.number_sample):\n",
    "                    u = 0\n",
    "                    for j in range(self.col_sample + 1):\n",
    "                        # Función de activación\n",
    "                        u = u + self.weight[j] * self.sample[i][j] \n",
    "\n",
    "                    y = self.sign(u) # Comprobar el valor del umbral\n",
    "\n",
    "                    if y != self.exit[i]:\n",
    "\n",
    "                        for j in range(self.col_sample+1):\n",
    "                            # Función de entrenamiento\n",
    "                            # w = w + N(d(k)-y) x(k)\n",
    "                            self.weight[j] = self.weight[j] + self.learn_rate * (self.exit[i]-y) * self.sample[i][j]\n",
    "                        erro = True\n",
    "\n",
    "                epoch_count = epoch_count+1 # Se aumenta el numero de epoch\n",
    "\n",
    "                if erro == False:\n",
    "                    print(('\\nEpoch: \\n', epoch_count)) # Mostramos el valor de epoch\n",
    "                    print('-'*20)\n",
    "                    print(\"\\n\")\n",
    "                    break\n",
    "\n",
    "    def sort(self, sample):\n",
    "            \"\"\"\n",
    "            Introducimos el bias,\n",
    "            sera una neurona que siempre estara activada.\n",
    "            \"\"\"\n",
    "            sample.insert(0, self.bias)\n",
    "            u = 0\n",
    "            for i in range(self.col_sample + 1):\n",
    "                # Función de activación\n",
    "                u = u + self.weight[i] * sample[i]\n",
    "\n",
    "            # Comprobamos el valor de la función de activación\n",
    "            y = self.sign(u) \n",
    "\n",
    "            # Si y es igual a -1, la clasificación corresponde a P1\n",
    "            if  y == -1:\n",
    "                print(('Ejemplo: ', numerales))\n",
    "                print('Clasificación: P1')\n",
    "            # Si y es igual a 1, la clasificación corresponde a P1\n",
    "            elif y == 1:\n",
    "                print(('Ejemplo: ', numerales))\n",
    "                print('Clasificación: P2')\n",
    "\n",
    "    def sign(self, u):\n",
    "        return 1 if u >= 0 else -1\n",
    "    \n",
    "# Datos de entrenamiento\n",
    "samples = [\n",
    "    [0, 2],\n",
    "    [-2, 2],\n",
    "    [0, -2],\n",
    "    [2, 0],\n",
    "    [-2,2],\n",
    "    [-2,-2],\n",
    "    [2,-2],\n",
    "    [2,2],\n",
    "]\n",
    "\n",
    "# Clasificación de los datos de entrenamiento (salidas que esperamos para cada conjunto de dato)\n",
    "\"\"\"\n",
    "[0,2] = 1\n",
    "[-2,-2] = 1\n",
    "[0,-2] = 0\n",
    "...\n",
    "\"\"\"\n",
    "exit = [1, 1, 0, 0, 1, 1, 0, 1]\n",
    "\n",
    "#Intancia de nuestra neurona\n",
    "network = MisNeuronas(sample=samples, exit = exit, learn_rate=0.01, epoch_number=1000, bias=-1)\n",
    " \n",
    "# Entrenamos a la neurona\n",
    "network.trannig()\n",
    "\n",
    "retur(network)\n",
    "\n",
    "\"\"\"\n",
    "pedimos datos y mostramos al usuario\n",
    "\"\"\"\n",
    "while True:\n",
    "    sample = []\n",
    "    for i in range(2):\n",
    "        sample.insert(i, float(input('Valor: ')))\n",
    "    network.sort(sample) # Clasificacipon de nuevos datos\n",
    "    print(\"\\n\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
